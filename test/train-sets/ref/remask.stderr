Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.368474   0.368474            3         3.0   0.0000   0.2909       57
0.317614   0.266754            6         6.0   1.0000   0.1073       31
0.232525   0.130418           11        11.0   0.0000   0.1409       38
0.260742   0.288959           22        22.0   1.0000   0.6627       88
0.221082   0.181422           44        44.0   0.0000   0.3158       66
0.212812   0.204350           87        87.0   1.0000   0.3954       61
0.193406   0.174000          174       174.0   1.0000   0.0558       26

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200
weighted label sum = 91
average loss = 0.187389
best constant = 0.455
best constant's loss = 0.247975
total feature number = 15482
