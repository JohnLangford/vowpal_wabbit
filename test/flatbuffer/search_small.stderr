Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/seq_small.cache
Reading datafile = train-sets/seq_small
num sources = 1
average    since      instance            current true      current predicted   cur   cur   predic    cache  examples          
loss       last        counter           output prefix          output prefix  pass   pol     made     hits    gener  beta    
4.000000   4.000000          1  [1 3 2 1 4 3         ] [1 1 1 1 1 1         ]     0     0        6        0        6  0.000000
2.500000   1.000000          2  [1 3 2 1 4 3         ] [1 3 2 1 3 3         ]     0     0       12        0       12  0.000000
1.250000   0.000000          4  [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]     0     0       24        0       24  0.000000
0.625000   0.000000          8  [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]     0     0       48        0       48  0.000000
0.312500   0.000000         16  [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]     1     0       96        0       96  0.000000
0.156250   0.000000         32  [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]     2     0      192        0      192  0.000000
0.078125   0.000000         64  [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]     5     0      384        0      384  0.000000
0.039062   0.000000        128  [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]    10     0      768        0      768  0.000000

finished run
number of examples per pass = 12
passes used = 12
weighted example sum = 144.000000
weighted label sum = 0.000000
average loss = 0.034722
total feature number = 2592
